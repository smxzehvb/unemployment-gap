{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ac4dccc",
   "metadata": {},
   "source": [
    "# Further discussion on breakpoint detection\n",
    "In this notebook, we explore in more detail the issue of detecting structural breaks in the regression of log(vacancy rate) on the log(unemployment rate).\n",
    "\n",
    "These breakpoints are needed because the Beveridge Elasticity is computed directly from this regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbdfdff",
   "metadata": {},
   "source": [
    "## Get our economic data\n",
    "For computing the BUG, we need:\n",
    "  * unemployment rate: u\n",
    "  * vacancy rate: v\n",
    "  * beveridge curve elasticity (computed from u, v, and breakpoints on the v/u series)\n",
    "  * social value of non-work (default is zeta = 0.26)\n",
    "  * recruting costs (default is kappa = 0.92)\n",
    "  \n",
    "For context in the plots, we also want recession information.\n",
    "<br>\n",
    "\n",
    "### Data source: \n",
    "\n",
    "![image.png](https://fred.stlouisfed.org/images/fred-logo-2x.png)\n",
    "<br>\n",
    "\n",
    "\n",
    "The St. Louis Fed has an [API](https://fred.stlouisfed.org/docs/api/fred/series_observations.html) which allows you to pull data programatically.\n",
    "You can do this yourself with a registered API key. (See [here](https://fred.stlouisfed.org/docs/api/api_key.html) for info.)\n",
    "\n",
    "*Or, we can use the handy FredReader class from the [pandas-datareader](https://pandas-datareader.readthedocs.io/en/latest/index.html) package!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a808b885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import timeit\n",
    "import ruptures as rpt\n",
    "from kneed import KneeLocator\n",
    "from pandas_datareader.fred import FredReader\n",
    "default_start_date = '1951-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a9eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bed8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16718fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recession information\n",
    "recession = FredReader('USREC', start=default_start_date).read()\n",
    "recession['starts'] = (recession.USREC- recession.USREC.shift(1) ==1)\n",
    "recession['ends'] = (recession.USREC- recession.USREC.shift(1) ==-1)\n",
    "starts = recession.index[recession['starts']==1].to_list()\n",
    "ends = recession.index[recession['ends']==1].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76322308",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = FredReader('UNRATE',start=default_start_date ).read()/100.0\n",
    "u = u.squeeze()\n",
    "u.index.freq = u.index.inferred_freq\n",
    "u_q = u.resample('Q').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9debd1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "hwi = pd.read_csv(\"../new_data/HWI_index.txt\", skiprows=6, header=None,delim_whitespace=True)\n",
    "hwi['date'] = pd.to_datetime(hwi[0].str[:4]+'-'+hwi[0].str[-2:]+'-01' )\n",
    "vac_proxy = pd.Series(data=pd.to_numeric(hwi[1].values),index=hwi['date'], name='help-wanted index') \n",
    "vac_proxy.index.freq = vac_proxy.index.inferred_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2290c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labor_lev = FredReader('CLF16OV', start=default_start_date).read().astype(float)\n",
    "nf_vac = FredReader('JTSJOL', start=default_start_date).read().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328ad5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vac_rate = nf_vac.JTSJOL/labor_lev.CLF16OV\n",
    "vac_rate.index.freq = vac_rate.index.inferred_freq\n",
    "v = pd.concat([vac_proxy.loc[:'2000-12-01']/100., vac_rate.loc['2001-01-01':]],)\n",
    "v_q = v.resample('Q').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4695c502",
   "metadata": {},
   "source": [
    "### Beveridge Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198afb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (7,7))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(np.log(u), np.log(v), linewidth=1, color='darkblue')\n",
    "\n",
    "bug.format_plot(ax, xgrid=False )\n",
    "\n",
    "plt.ylabel('Log Vacancy Rate', fontsize=12)\n",
    "plt.xlabel('Log Unemployment Rate', fontsize=12)\n",
    "plt.title('Beveridge Curve (monthly)', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2651fa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_q.index = u_q.index.to_period('Q')\n",
    "v_q.index = v_q.index.to_period('Q')\n",
    "\n",
    "log_u_q = np.log(u_q)\n",
    "log_v_q = np.log(v_q)\n",
    "\n",
    "last_index = min(log_u_q.last_valid_index(), log_v_q.last_valid_index())\n",
    "log_u_q = log_u_q.loc[:last_index]\n",
    "log_v_q = log_v_q.loc[:last_index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1667d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (7,7))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(log_u_q, log_v_q, linewidth=1,color='darkblue')\n",
    "\n",
    "bug.format_plot(ax, xgrid=False)\n",
    "\n",
    "plt.ylabel('Log Vacancy Rate', fontsize=12)\n",
    "plt.xlabel('Log Unemployment Rate', fontsize=12)\n",
    "plt.title('Beveridge Curve (quarterly)', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9670dff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62fe2c9c",
   "metadata": {},
   "source": [
    "## ruptures package\n",
    "We are leveraging the [ruptures](https://centre-borelli.github.io/ruptures-docs/) package in python to perform the breakpoint detection. The package implements most of the algorithms surveyed in the paper: C.Truong, L.Oudre, N.Vayatis. (2020) \"Selective review of offline change point detection methods.\" *Signal Processing*, 167:107299. [pdf](http://www.laurentoudre.fr/publis/TOG-SP-19.pdf)\n",
    "\n",
    "The design of the rutures package allows the user to seperatly specify the [search method](https://centre-borelli.github.io/ruptures-docs/user-guide/detection/dynp/) and the [cost function](https://centre-borelli.github.io/ruptures-docs/user-guide/costs/costl1/); thus, allowing for modular composition of breakpoint detection approaches. Different compositions will correspond to different algorithms in the literature.\n",
    "\n",
    "\n",
    "For example, using `rpt.Dynp` for the dynamic programing search and `rpt.costs.CostLinear` as the cost function, we get an implementation of the Bai-Perron (2003) algorithm that is used in the Michaillat & Saez paper. ([M&S GitHub link](https://github.com/pascalmichaillat/unemployment-gap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ee63ea",
   "metadata": {},
   "source": [
    "### Search methods\n",
    "The ruptures package implements 6 different search methods for finding breakpoints.\n",
    "  * `Dynp`: \"It finds the (exact) minimum of the sum of costs by computing the cost of all subsequences of a given signal. It is called \"dynamic programming\" because the search over all possible segmentations is ordered using a dynamic programming approach.\" This is the method used in Bai-Perron. *Works with pre-specified number of break-points.* \n",
    "  * `Pelt`: This algorithm relies on a pruning rule to find an approximate solution when the enumeration of all possible partitions is impractical or impossible. *Works when number of breakpoints is unknown.* (Uses a penatly parameter to select number of breakpoints, rather than specifying the number directly.)\n",
    "  * `KernelCPD`: A faster C implementation that can perform both dynamic programming and PELT.\n",
    "  * `Bingseg`: A very simple, greedy binary segmentation approach. Advantages include very low complexity and can be used when number of breakpoints/sub-series regimes is known or unknown.\n",
    "  * `BottomUp`: Another simple approach like binary segmentation, with similar advantages (Low complexity and can work with known or unknown number of breakpoints). But this one is generous, not greedy.\n",
    "  * `Window`: Another simple approach based on sliding windows. As with bottom-up or binary segnmentaton, it has low complexity and can work with known or unknown number of breakpoints. Window width parameter needs to be smaller than the minimum sub-series length, so may not work for detecting short sub-series. \n",
    "  \n",
    "### Let's try...\n",
    "Our series are not too long (857 for monthly or 286 for quarterly), so computational complexity is not much of a concern. We discard the choices of `Pelt` and `KernelCPD` for this reason. We also remove the `Window` method from contention because the small window size needed to detect the 8 quarters post-COVID regime is likely too small to give robust breakpoint estimates overall.\n",
    "\n",
    "\n",
    "So we will try the simple methods, `Binseg` and `BottomUp`, and compare them to the `Dynp` method (Dynp is equivalent to the method used in B-P)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c512b06c",
   "metadata": {},
   "source": [
    "### Cost functions\n",
    "Besides `CostLinear`, there are 9 other cost functions available in ruptures, as well as a method for declaring a custom cost. (See [here](https://centre-borelli.github.io/ruptures-docs/user-guide/costs/costcustom/).) Should we try any of these? \n",
    "\n",
    "*No.*\n",
    "\n",
    "Actually, in this application, `CostLinear` appears most appropriate. Several of the other cost functions operate on univariate series only, so they do not incorporate covariates, which we need in this case.\n",
    "\n",
    "In this application, *y=log(vacanacy)*, and *x=log(unemployment)*, and we find the breakpoints such that the sum of the squared residuals across peice-wise OLS regressions is minimized. Not only does that give us our breakpoints, but this also immediately gives us the quantity we desire, the Beverdige elasticity, as elasticity is the simply the negative of the OLS estimated coeff for log(unemployment).\n",
    "\n",
    "Therefore linear cost seems the most appropriate for this application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051c5bb4",
   "metadata": {},
   "source": [
    "## Experiments with breakpoint detection\n",
    "### Fixing number fo breakpoints\n",
    "\n",
    "Recall the breakpoints from the M&S paper were [0, 41, 84, 153, 194, 235, 276].\n",
    "\n",
    "Note that was 5 breakpoints for the period 1951--2019, whereas we now are looking at 6 breakpoints for 1951--current year.\n",
    "\n",
    "#### Timing tests\n",
    "To run timing tests, uncomment the lines with the %timeit magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc4f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bkps = 6\n",
    "min_size = 7\n",
    "model ='linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512dad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the data in the format that ruptures package likes\n",
    "y = np.array(log_v_q)\n",
    "X = np.vstack((np.array(log_u_q), np.ones(len(y)))).T\n",
    "signal = np.column_stack((y.reshape(-1, 1), X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6a5245",
   "metadata": {},
   "source": [
    "## Dynamic programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bf5b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_dynp = rpt.Dynp(model=model, min_size=min_size, jump=1).fit(signal)\n",
    "%timeit fit_dynp = rpt.Dynp(model=model, min_size=min_size, jump=1).fit(signal) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e25680",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_dynp = fit_dynp.predict(n_bkps=n_bkps)\n",
    "%timeit est_dynp = fit_dynp.predict(n_bkps=n_bkps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966073bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_dynp.insert(0,0)\n",
    "est_dynp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed66b92",
   "metadata": {},
   "source": [
    "### Plot of Bev Elasticity calculated from Dynamic Programming\n",
    "#### (This is the M&S Paper method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735b86e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_dynp, _ = bug.compute_beveridge_elasticity(u_q, v_q, bkps_in=est_dynp)\n",
    "\n",
    "bug.plot_beveridge_elasticity_series(e_dynp, recession_dates=[starts, ends], draw_legend=True)\n",
    "plt.ylim(0,1.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87a723c",
   "metadata": {},
   "source": [
    "## Binary Segmentation\n",
    "Specified number of breakpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e256a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_bin = rpt.Binseg(model=model, min_size=min_size, jump=1).fit(signal)\n",
    "%timeit fit_bin = rpt.Binseg(model=model, min_size=min_size, jump=1).fit(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a73f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_bin = fit_bin.predict(n_bkps=n_bkps)\n",
    "%timeit est_bin = fit_bin.predict(n_bkps=n_bkps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ce0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_bin.insert(0,0)\n",
    "est_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bc3c02",
   "metadata": {},
   "source": [
    "### Plot of Bev Elasticity calculated from Binary Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8eaa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_bin, _ = bug.compute_beveridge_elasticity(u_q, v_q, bkps_in=est_bin)\n",
    "bug.plot_beveridge_elasticity_series(e_bin, recession_dates=[starts, ends], draw_legend=True)\n",
    "plt.ylim(0,1.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bc5e84",
   "metadata": {},
   "source": [
    "### Bottom-Up\n",
    "Specified number of breakpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad9407",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_bup = rpt.BottomUp(model=model, min_size=min_size, jump=1).fit(signal)\n",
    "%timeit fit_bup = rpt.BottomUp(model=model, min_size=min_size, jump=1).fit(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cecab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_bup = fit_bup.predict(n_bkps=n_bkps)\n",
    "%timeit est_bup = fit_bup.predict(n_bkps=n_bkps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9466de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_bup.insert(0,0)\n",
    "est_bup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21660d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_bup, _ = bug.compute_beveridge_elasticity(u_q, v_q, bkps_in=est_bup)\n",
    "bug.plot_beveridge_elasticity_series(e_bup, recession_dates=[starts, ends], draw_legend=True)\n",
    "plt.ylim(0,1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b62d9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_6_breaks = pd.DataFrame({'Paper':[0, 41, 84, 153, 194, 235, 275, 'NA'], \n",
    "                                 'DynProg':est_dynp, 'BottomUp':est_bup, \n",
    "                                 'BinarySeg':est_bin, })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602f0b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_6_breaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaa4ca3",
   "metadata": {},
   "source": [
    "## The resulting estimated BUG for different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70714695",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_ref, _ = bug.compute_beveridge_elasticity(u_q, v_q, \n",
    "                                         bkps_in=np.array([0, 41, 84, 153, 194, 235, 275, 286]) )\n",
    "gap_ref = bug.compute_unemployment_gap(u_q, v_q, e_ref['E'])\n",
    "gap_dynp = bug.compute_unemployment_gap(u_q, v_q, e_dynp['E'])\n",
    "gap_bin = bug.compute_unemployment_gap(u_q, v_q, e_bin['E'])\n",
    "gap_bup = bug.compute_unemployment_gap(u_q, v_q, e_bup['E'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8131162",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gap_dynp.plot( linewidth=3, figsize=(9, 6), label='Dynamic Prog')\n",
    "gap_bin.plot(ax=ax, linewidth=2, label='Binary Seg')\n",
    "gap_bup.plot(ax=ax, linewidth=2, color='k',linestyle='dashed',label='Bottom Up')\n",
    "plt.axhline(y=0, color='magenta', linewidth=2,)\n",
    "\n",
    "for b in summary_6_breaks.DynProg[1:-1]:\n",
    "    plt.axvline(x=u_q.index[b], color='blue', linewidth=1)\n",
    "\n",
    "for b in summary_6_breaks.BinarySeg[1:-1]:\n",
    "    plt.axvline(x=u_q.index[b], color='red', linewidth=1)\n",
    "    \n",
    "for b in summary_6_breaks.BottomUp[1:-1]:\n",
    "    plt.axvline(x=u_q.index[b], color='black', linewidth=1)\n",
    "    \n",
    "plt.legend()\n",
    "plt.ylim(-.02,.1)\n",
    "bug.format_plot(ax, [starts,ends])\n",
    "plt.ylabel('Unemployment Gap', fontsize=12)\n",
    "plt.title('Unemployment Gap', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76983b76",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "We see the resulting breakpoints between the three methods are quite similar, especially for the period after 1972. This leads to the estimated BUG being similar as well.\n",
    "\n",
    "There are more differences in the earlier part of the series.\n",
    "\n",
    "But since the dynamic programming method finds an *exact* solution to minimizing the sum of costs (recall cost is SSR in this case), the main reason to favor a different algorithm like Binary Segmentation or Bottom-up would be computational. In our case, we have short series, and we actually found the Dynamic Porgramming method to be the **FASTEST!**\n",
    "\n",
    "## Number of breakpoints\n",
    "The experiments above with search method assumed the correct number of breakpoints was known. (We assumed 6 in this case.)\n",
    "\n",
    "Let's investigate.\n",
    "\n",
    "The Binseg or BottomUp search methods can be used with a penalty parameter to determine the number of breakpoints. But that still relies on some rules-of-thumb for setting that penalty.\n",
    "\n",
    "And from above, we have seen the Dynamic Porgramming approach is the fastest anyway. \n",
    "\n",
    "So, we can just cycle through a number of breakpoints, and see what it looks like:\n",
    "\n",
    "## Different num breakpoints w/ Dynamic Prog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc2f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_dynp = rpt.Dynp(model='linear', min_size=10, jump=1).fit(signal)\n",
    "_ = fit_dynp.predict(n_bkps=10)\n",
    "num_breaks = [8,6,4,2]\n",
    "for b in num_breaks:\n",
    "    est_dynp = fit_dynp.predict(n_bkps=b)\n",
    "    est_dynp.insert(0,0)\n",
    "    e_dynp, _ = bug.compute_beveridge_elasticity(u_q, v_q, bkps_in=est_dynp)\n",
    "    bug.plot_beveridge_elasticity_series(e_dynp, \n",
    "                                         recession_dates=[starts, ends], \n",
    "                                         draw_legend=True, legend_loc=1)  \n",
    "    plt.ylim(0,1.5)\n",
    "    plt.title('num breaks: '+str(len(est_dynp)-2), fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f8439d",
   "metadata": {},
   "source": [
    "### How to decide the number of breaks\n",
    "Other than just eyeballing?\n",
    "\n",
    "Bai & Perron (2003) suggest supF type tests; e.g. for no break (*m=0*) vs *m=k* breaks. Further, this can be extended to test of *m* breaks vs *m+1* breaks. The possibility of examining BIC or other information criteria is also discussed, but B-P warn this sometimes fails under conditions of serial dependence in the errors. \n",
    "\n",
    "The ruptures package does not include hypothesis testing for determining the number of breaks, so we'll have to write some evaluation tools for ourselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e075c2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the data in the format that ruptures package likes\n",
    "y = np.array(log_v_q)\n",
    "X = np.vstack((np.array(log_u_q), np.ones(len(y)))).T\n",
    "signal = np.column_stack((y.reshape(-1, 1), X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648dd618",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bkps_max =12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e860cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "Eval = bug.evaluate_num_breaks(signal, n_bkps_max, min_size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8f7a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = KneeLocator(np.arange(0,n_bkps_max + 1), Eval.ssr, curve=\"convex\", direction=\"decreasing\")\n",
    "ax = k.plot_knee()\n",
    "plt.title('SSR')\n",
    "plt.xlabel(\"Number of change points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ea9b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = KneeLocator(np.arange(0,n_bkps_max + 1), Eval.bic, curve=\"convex\", direction=\"decreasing\")\n",
    "ax = k.plot_knee()\n",
    "plt.title('BIC')\n",
    "plt.xlabel(\"Number of change points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc72fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = KneeLocator(np.arange(0,n_bkps_max + 1), Eval.lwz, curve=\"convex\", direction=\"decreasing\")\n",
    "ax = k.plot_knee()\n",
    "plt.title('LWZ Modified BIC')\n",
    "plt.xlabel(\"Number of change points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78870610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the knee found on LWZ\n",
    "chosen_k = k.knee\n",
    "opt = Eval.bkps[chosen_k]\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56f54d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_opt, coeffs_opt = bug.compute_beveridge_elasticity(log_u_q, log_v_q, bkps_in=opt )\n",
    "gap_opt = bug.compute_unemployment_gap(u_q, v_q, e_opt['E'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e24174",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_bks = [u_q.index[b] for b in opt[:-1]]\n",
    "in_bks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1103b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = bug.plot_beveridge_gap_series(gap_opt, in_bks, recession_dates=[starts, ends], )\n",
    "\n",
    "plt.ylim(-.02,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e13d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bug.plot_beveridge_elasticity_series(e_opt, recession_dates=[starts, ends], draw_legend=True)\n",
    "plt.ylim(-.04,2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c0764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bug.plot_beveridge_curve_segments(log_u_q, log_v_q, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c0bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bug.plot_beveridge_curve_fits(log_u_q, log_v_q, opt, coeffs_opt, figsize=(7,7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
